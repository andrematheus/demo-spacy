{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Tokenização com spaCY\n",
    "\n",
    "Tokenização é o processo de quebrar um documento em representações padronizadas de palavras, bem como pontuação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from utils import table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## As tabelas apresentam as seguintes informações:\n",
    "\n",
    "Text: The original word text.\n",
    "\n",
    "Lemma: The base form of the word.\n",
    "\n",
    "POS: The simple part-of-speech tag.\n",
    "\n",
    "Tag: The detailed part-of-speech tag.\n",
    "\n",
    "Dep: Syntactic dependency, i.e. the relation between tokens.\n",
    "\n",
    "Shape: The word shape – capitalisation, punctuation, digits.\n",
    "\n",
    "is alpha: Is the token an alpha character?\n",
    "\n",
    "is stop: Is the token part of a stop list, i.e. the most common words of the language?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>Token  </th><th>Text  </th><th>Lemma  </th><th>Pos  </th><th>Tag  </th><th>Dep  </th><th>Shape  </th><th>Alpha  </th><th>Stop  </th><th>Vectors                              </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>The    </td><td>The   </td><td>the    </td><td>DET  </td><td>DT   </td><td>det  </td><td>Xxx    </td><td>True   </td><td>False </td><td>[0.80844855 0.3608573  0.33025062]   </td></tr>\n",
       "<tr><td>quick  </td><td>quick </td><td>quick  </td><td>ADJ  </td><td>JJ   </td><td>amod </td><td>xxxx   </td><td>True   </td><td>False </td><td>[-2.8631718   1.2935665  -0.41818553]</td></tr>\n",
       "<tr><td>brown  </td><td>brown </td><td>brown  </td><td>ADJ  </td><td>JJ   </td><td>amod </td><td>xxxx   </td><td>True   </td><td>False </td><td>[ 0.32616964 -0.5881793   0.35415274]</td></tr>\n",
       "<tr><td>fox    </td><td>fox   </td><td>fox    </td><td>NOUN </td><td>NN   </td><td>nsubj</td><td>xxx    </td><td>True   </td><td>False </td><td>[0.01345855 2.4567297  0.983789  ]   </td></tr>\n",
       "<tr><td>jumps  </td><td>jumps </td><td>jump   </td><td>VERB </td><td>VBZ  </td><td>ROOT </td><td>xxxx   </td><td>True   </td><td>False </td><td>[-1.9692165   1.5927204   0.08396843]</td></tr>\n",
       "<tr><td>over   </td><td>over  </td><td>over   </td><td>ADP  </td><td>IN   </td><td>prep </td><td>xxxx   </td><td>True   </td><td>True  </td><td>[ 1.4140642  -0.77489394  1.6844326 ]</td></tr>\n",
       "<tr><td>the    </td><td>the   </td><td>the    </td><td>DET  </td><td>DT   </td><td>det  </td><td>xxx    </td><td>True   </td><td>True  </td><td>[-0.06463796 -0.11468069  0.7628046 ]</td></tr>\n",
       "<tr><td>lazy   </td><td>lazy  </td><td>lazy   </td><td>ADJ  </td><td>JJ   </td><td>amod </td><td>xxxx   </td><td>True   </td><td>False </td><td>[-1.3845627  -2.287334   -0.63253677]</td></tr>\n",
       "<tr><td>dog    </td><td>dog   </td><td>dog    </td><td>NOUN </td><td>NN   </td><td>pobj </td><td>xxx    </td><td>True   </td><td>False </td><td>[1.8463812 2.2142866 2.3155878]      </td></tr>\n",
       "<tr><td>.      </td><td>.     </td><td>.      </td><td>PUNCT</td><td>.    </td><td>punct</td><td>.      </td><td>False  </td><td>False </td><td>[ 3.6785886  -0.66314685  1.61094   ]</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nlp_en = spacy.load('en')\n",
    "\n",
    "en_str = \"The quick brown fox jumps over the lazy dog.\"\n",
    "en_doc = nlp_en(en_str)\n",
    "\n",
    "rows = [[token,\n",
    "         token.text,\n",
    "         token.lemma_,\n",
    "         token.pos_,\n",
    "         token.tag_,\n",
    "         token.dep_,\n",
    "         token.shape_,\n",
    "         token.is_alpha,\n",
    "         token.is_stop,\n",
    "         token.vector[0:3]] for token in en_doc]\n",
    "headers = [\"Token\", \"Text\", \"Lemma\", \"Pos\", \"Tag\", \"Dep\", \"Shape\", \"Alpha\", \"Stop\", \"Vectors\"]\n",
    "table(headers, rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
